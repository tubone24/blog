{"componentChunkName":"component---src-templates-blog-post-tsx","path":"/2020/05/03/stylegan2-anime","result":{"data":{"content":{"edges":[{"node":{"id":"3f320438-4751-5013-b031-adad98aefd91","excerpt":"Jetson Nanoを買ってから機械学習熱が再来したので頑張ります。 Table of Contents GCGANで美少女キャラ無限増殖 GANの革命児 StyleGAN Progressive Growing スタイル変換 Style Transfer…","fields":{"slug":"2020/05/03/stylegan2-anime"},"frontmatter":{"id":null,"title":"StyleGANとStyleGAN2を使って美少女キャラを無限増殖させる","slug":"2020/05/03/stylegan2-anime","date":"2020-05-03T09:48:45.329Z","headerImage":"https://i.imgur.com/VfRjfpW.png","tags":["機械学習","StyleGAN"]}}}]}},"pageContext":{"id":"3f320438-4751-5013-b031-adad98aefd91","index":38,"repHtml":"<p>Jetson Nanoを買ってから機械学習熱が再来したので頑張ります。</p>\n<h2 id=\"table-of-contents\" style=\"position:relative;\"><a href=\"#table-of-contents\" aria-label=\"table of contents permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Table of Contents</h2>\n<div class=\"toc\">\n<ul>\n<li>\n<p><a href=\"#gcgan%E3%81%A7%E7%BE%8E%E5%B0%91%E5%A5%B3%E3%82%AD%E3%83%A3%E3%83%A9%E7%84%A1%E9%99%90%E5%A2%97%E6%AE%96\">GCGANで美少女キャラ無限増殖</a></p>\n</li>\n<li>\n<p><a href=\"#gan%E3%81%AE%E9%9D%A9%E5%91%BD%E5%85%90-stylegan\">GANの革命児 StyleGAN</a></p>\n<ul>\n<li><a href=\"#progressive-growing\">Progressive Growing</a></li>\n<li><a href=\"#%E3%82%B9%E3%82%BF%E3%82%A4%E3%83%AB%E5%A4%89%E6%8F%9B-style-transfer\">スタイル変換 Style Transfer</a></li>\n<li><a href=\"#%E6%BD%9C%E5%9C%A8%E5%A4%89%E6%95%B0%E3%81%8B%E3%82%89%E7%94%BB%E5%83%8F%E3%82%92%E4%BD%9C%E3%82%89%E3%81%9A%E3%81%A1%E3%82%83%E3%82%93%E3%81%A8style%E3%82%92n%E6%9C%AC%E5%8A%A0%E3%81%88%E5%85%A5%E3%82%8C%E3%82%8D\">潜在変数から画像を作らずちゃんとStyleをn本加え入れろ～</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#%E6%85%A3%E3%82%8C%E3%81%AA%E3%81%84%E8%A7%A3%E8%AA%AC%E3%81%AF%E3%82%82%E3%81%86%E3%82%84%E3%82%89%E3%81%AA%E3%81%84%E6%9C%AC%E9%A1%8C%E3%81%AB%E6%88%BB%E3%82%8A%E3%81%BE%E3%81%99\">慣れない解説はもうやらない、本題に戻ります</a></p>\n</li>\n<li>\n<p><a href=\"#making-anime-faces-with-stylegan\">Making Anime Faces With StyleGAN</a></p>\n</li>\n<li>\n<p><a href=\"#stylegan%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6%E3%81%BF%E3%82%8B\">StyleGANを使ってみる</a></p>\n</li>\n<li>\n<p><a href=\"#a%E3%81%8B%E3%82%89b%E3%81%AB%E7%94%BB%E5%83%8F%E3%82%92%E9%81%B7%E7%A7%BBtransition%E3%81%95%E3%81%9B%E3%82%8B\">AからBに画像を遷移(Transition)させる</a></p>\n</li>\n<li>\n<p><a href=\"#stylegan2%E3%81%A7%E3%82%82%E7%BE%8E%E5%B0%91%E5%A5%B3%E7%84%A1%E9%99%90%E5%A2%97%E6%AE%96\">StyleGAN2でも美少女無限増殖</a></p>\n<ul>\n<li><a href=\"#%E3%81%8A%E3%82%84%E5%8B%95%E3%81%8B%E3%81%AA%E3%81%84\">おや!?動かない。</a></li>\n<li><a href=\"#%E3%81%BE%E3%81%A0%E3%81%86%E3%81%BE%E3%81%8F%E5%8B%95%E3%81%8B%E3%81%AA%E3%81%84\">まだうまく動かない</a></li>\n<li><a href=\"#nvcc-error--cudafe-died-with-status-0xc0000005-access_violation\">nvcc error : 'cudafe++' died with status 0xC0000005 (ACCESS_VIOLATION)</a></li>\n<li><a href=\"#3%E5%BA%A6%E7%9B%AE%E3%81%AE%E6%AD%A3%E7%9B%B4\">3度目の正直</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#%E7%B5%90%E8%AB%96\">結論</a></p>\n</li>\n<li>\n<p><a href=\"#%E5%8F%82%E8%80%83\">参考</a></p>\n</li>\n</ul>\n</div>\n<h2 id=\"gcganで美少女キャラ無限増殖\" style=\"position:relative;\"><a href=\"#gcgan%E3%81%A7%E7%BE%8E%E5%B0%91%E5%A5%B3%E3%82%AD%E3%83%A3%E3%83%A9%E7%84%A1%E9%99%90%E5%A2%97%E6%AE%96\" aria-label=\"gcganで美少女キャラ無限増殖 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>GCGANで美少女キャラ無限増殖</h2>\n<p>GAN(Generative Adversarial Networks)とは日本語では<strong>敵対的生成ネットワーク</strong>と呼ばれる機械学習フレームワークで、現実には存在しないそれっぽい画像を生成する方法などで採用されています。</p>\n<p>GANの詳しい仕組みについては専門家にゆだねるとしてフェイク画像を生成する<strong>Generator</strong>とそれがフェイクかどうか判断する<strong>Discriminator</strong>の2種類が互いに勝負しあうことで画像生成の精度を高くしていく、という感じです。</p>\n<p>いらすとやでイメージを作ってみました。</p>\n<p><img class=\"lozad\" src=\"data:image/gif;base64,R0lGODlhAQABAGAAACH5BAEKAP8ALAAAAAABAAEAAAgEAP8FBAA7\" data-src=\"https://i.imgur.com/SVZB0Wi.png\" alt=\"img\"></p>\n<p>必死に偽物の言動を本物っぽく言う不審者と、嘘を見破る警察官（探偵）という構図が比喩としては一般的です。</p>\n<p>GANについては、実は昔(今から2年前)録画サーバーで全アニメを録画していた頃、その動画ファイルから64×64のアニメ顔画像データ58000件を抽出し、それを使ってGAN(正確には<strong>DCGAN</strong>)でアニメ顔を生成する活動に取り組んだことがあります。</p>\n<p>DCGANについても詳細は専門家に任せます。<a href=\"https://arxiv.org/pdf/1511.06434.pdf\" target=\"_blank\" rel=\"noopener noreferrer\">これ</a>が論文です。</p>\n<p>しっかり論文が読みこなせるマンになりたい..。</p>\n<p>端的に言えばGANの学習の不安定さを<strong>畳み込み層</strong>や<strong>Batch Normalization</strong>、tanh、 Leaky ReLUなどのReLU以外の<strong>活性化関数</strong>を採用したりして学習の安定化を図ってます。</p>\n<p>当時はChainerの<a href=\"https://github.com/chainer/chainer/tree/master/examples/dcgan\" target=\"_blank\" rel=\"noopener noreferrer\">Example</a>を改造して学習から推論をやりましたがあまりうまくいきませんでした。</p>\n<p>その時作ったモデルの結果がこちらです。</p>\n<iframe loading=\"lazy\" width=\"200\" height=\"150\" src=\"https://www.youtube.com/embed/FhBeuX4cYoE?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Chainer DCGAN Animeface\"></iframe>\n<p>解像度が64×64なので、うーん大したことありませんね。</p>\n<p>というより家のPC程度のGPUでは限界がありそうなことが分かったので美少女キャラを大量生成して薔薇色の生活空間を作る計画はかないませんでした。</p>\n<p>しかし、GCGANで美少女無限増殖はGANの基礎やアニメ顔の抜き出し方、OpenCVの使い方など学ぶことは多かったような気がします。</p>\n<h2 id=\"ganの革命児-stylegan\" style=\"position:relative;\"><a href=\"#gan%E3%81%AE%E9%9D%A9%E5%91%BD%E5%85%90-stylegan\" aria-label=\"ganの革命児 stylegan permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>GANの革命児 StyleGAN</h2>\n<p>あきらめていた美少女無限増殖ですが、最近<a href=\"https://blog.tubone-project24.xyz/2020/04/21/jetson-nano\" target=\"_blank\" rel=\"noopener noreferrer\">Jetson Nanoを買った</a>のでせっかくなのでまたGANに挑戦しようと思いました。</p>\n<p>さて、最近GANなんて触っていなかったので気が付かなかったのですが、<a href=\"https://arxiv.org/pdf/1812.04948.pdf\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>StyleGAN</strong></a>というのが盛り上がっている（いた？）と知ります。</p>\n<p>まずは下記の画像を見てください。</p>\n<p><img class=\"lozad\" src=\"data:image/gif;base64,R0lGODlhAQABAGAAACH5BAEKAP8ALAAAAAABAAEAAAgEAP8FBAA7\" data-src=\"https://i.imgur.com/9mP8aH2.jpg\" alt=\"img\">\n(<a href=\"https://en.wikipedia.org/wiki/StyleGAN\" target=\"_blank\" rel=\"noopener noreferrer\">https://en.wikipedia.org/wiki/StyleGAN</a>)</p>\n<p>この美女のポートレート、どこかの女優さんかと思いきやStyleGANで生成されたらしいです。</p>\n<p>いわれてみれば後ろ髪が不自然な気もしますが、これはわかりませんね。すごい。</p>\n<p>StyleGANを作ったのはあの<a href=\"https://www.nvidia.com/ja-jp/\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>NVIDIA</strong></a>、つまりGPU作成お化けが作ったGANで、GPUのパワーをふんだんに使ったネットワークとして知られています。</p>\n<p>StyleGANの詳しいことは専門家に任せるとして、さらっとエクストリーム解説頑張ってみたいと思います。</p>\n<h3 id=\"progressive-growing\" style=\"position:relative;\"><a href=\"#progressive-growing\" aria-label=\"progressive growing permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Progressive Growing</h3>\n<p>GANで1024x1024などの高解像度画像を生成するのは至難の業です。</p>\n<p>高解像度の画像を学習させるとモデルの評価指数多すぎて、Generatorが生み出す画像が<strong>これじゃない...</strong> 感満載な画像ができることが知られてます。</p>\n<p>そこでStyleGANは高解像度の画像を生成するために<strong>Progressive Growing</strong>という手法を採用しました。</p>\n<p><img class=\"lozad\" src=\"data:image/gif;base64,R0lGODlhAQABAGAAACH5BAEKAP8ALAAAAAABAAEAAAgEAP8FBAA7\" data-src=\"https://i.imgur.com/bTE91Hx.png\" alt=\"img\">\n(<a href=\"https://arxiv.org/abs/1710.10196\" target=\"_blank\" rel=\"noopener noreferrer\">Progressive Growing of GANs for Improved Quality, Stability, and Variation</a>)</p>\n<p>画像生成プロセスを<strong>一気に高解像度の画像を生成するのではなく低解像度から漸近的(≒徐々に近づける)に高解像度の画像を成長させる</strong>手法になります。</p>\n<p>この手法はStyleGANの前身研究の<a href=\"https://arxiv.org/abs/1710.10196\" target=\"_blank\" rel=\"noopener noreferrer\">PGGAN(Progressive Growing of GANs)</a>の成果物です。</p>\n<h3 id=\"スタイル変換-style-transfer\" style=\"position:relative;\"><a href=\"#%E3%82%B9%E3%82%BF%E3%82%A4%E3%83%AB%E5%A4%89%E6%8F%9B-style-transfer\" aria-label=\"スタイル変換 style transfer permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>スタイル変換 Style Transfer</h3>\n<p>もう一つの特徴はスタイル変換(<a href=\"https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf\" target=\"_blank\" rel=\"noopener noreferrer\">Style Transfer</a>)と呼ばれる技術を使っていることです。</p>\n<p><img class=\"lozad\" src=\"data:image/gif;base64,R0lGODlhAQABAGAAACH5BAEKAP8ALAAAAAABAAEAAAgEAP8FBAA7\" data-src=\"https://i.imgur.com/9EAE63P.png\" alt=\"img\">\n(<a href=\"https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf\" target=\"_blank\" rel=\"noopener noreferrer\">Image Style Transfer Using Convolutional Neural Networks</a>)</p>\n<p>上の画像は<a href=\"https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf\" target=\"_blank\" rel=\"noopener noreferrer\">Image Style Transfer Using Convolutional Neural Networks</a>からの引用ですが特定の画像に画風(Style)情報を差し込むことで任意の画風に変換できる、というものです。</p>\n<p><a href=\"https://prisma-ai.com/\" target=\"_blank\" rel=\"noopener noreferrer\">PRISMA</a>というサイトで遊んだことのあるほうも多いかと思いますが、まさにあれです。</p>\n<p>StyleGANではStyle Transferに<a href=\"https://arxiv.org/pdf/1703.06868.pdf\" target=\"_blank\" rel=\"noopener noreferrer\"><strong>AdaIN(Adaptive Instance Normalization)</strong></a>という手法を使ってます。</p>\n<p>今までのStyle Transfer(Instance Normalization)は変換したいStyle画像をStyle用ベクトルとして学習し、指定したStyleごとに選択的にモデルに係数とバイアスを設定することで実現してました。</p>\n<p>AdaINの手法ではStyleを適用画像、Style画像チャネルごとの平均と標準偏差から導きます。</p>\n<p><img class=\"lozad\" src=\"data:image/gif;base64,R0lGODlhAQABAGAAACH5BAEKAP8ALAAAAAABAAEAAAgEAP8FBAA7\" data-src=\"https://i.imgur.com/z7ZpFko.png\" alt=\"img\">\n(<a href=\"https://arxiv.org/abs/1703.06868\" target=\"_blank\" rel=\"noopener noreferrer\">Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization</a>)</p>\n<p>統計量を用いることで、学習していないStyleについてもそれなりに対応できる、というのがメリットのようです。</p>\n<h3 id=\"潜在変数から画像を作らずちゃんとstyleをn本加え入れろ\" style=\"position:relative;\"><a href=\"#%E6%BD%9C%E5%9C%A8%E5%A4%89%E6%95%B0%E3%81%8B%E3%82%89%E7%94%BB%E5%83%8F%E3%82%92%E4%BD%9C%E3%82%89%E3%81%9A%E3%81%A1%E3%82%83%E3%82%93%E3%81%A8style%E3%82%92n%E6%9C%AC%E5%8A%A0%E3%81%88%E5%85%A5%E3%82%8C%E3%82%8D\" aria-label=\"潜在変数から画像を作らずちゃんとstyleをn本加え入れろ permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>潜在変数から画像を作らずちゃんとStyleをn本加え入れろ～</h3>\n<p>さて、長くなってきましたがそろそろ解説終わりです。</p>\n<p>StyleGANではPGGANの成果物であるProgressive Growingを継承しつつも画像生成のプロセスが異なります。</p>\n<p><img class=\"lozad\" src=\"data:image/gif;base64,R0lGODlhAQABAGAAACH5BAEKAP8ALAAAAAABAAEAAAgEAP8FBAA7\" data-src=\"https://i.imgur.com/7xOURgl.png\" alt=\"img\">\n(<a href=\"https://arxiv.org/pdf/1812.04948.pdf\" target=\"_blank\" rel=\"noopener noreferrer\">A Style-Based Generator Architecture for Generative Adversarial Networks\n</a>)</p>\n<p>StyleGANでは、PGGANとは異なり入力に潜在変数を直接用いません。<strong>const(固定値)のテンソル</strong>を用いています。</p>\n<p>その代わり、<strong>ネットワークの各層にAdaINを用いStyleを適用</strong>することで画像に変化を生み出しているのです。</p>\n<p>また、単純に潜在変数をAdaINにぶち込んでいるわけでもなく、<strong>MappingNetwork(全結合ニューラルネット)で潜在変数を非線形化</strong>してから用いるなど細やかな気配りもされています。</p>\n<p>なぜStyleを各層に適用する形をとるかというと、人やものが映った画像にはさまざまな特徴量があり、GANはそれらの特徴量を学習することで画像生成していますが、実際人が映った画像には顔の向きや顔の輪郭など大きな特徴から目の色、肌の色のようなテクスチャ、肌荒れや髪の毛の巻き方などみみっちい特徴までさまざまです。</p>\n<p>一様な特徴量で表すのは限界があるのです。</p>\n<p>実はStyleGANはここらへんをしっかり考えていて、Style適用に加え<strong>Mixing Regularization</strong>という複数の潜在変数(ここではStyleベクトル)を各種層で混ぜ込んで適用するという手法で解決してます。</p>\n<p>Progressive Growingで申したとおり、各層は低解像度から高解像度へと進むのですがStyleベクトルを低解像度の際に適用した場合と高解像度の際に適用した場合では<strong>低解像度の際に入れたStyleのほうが画像への寄与が大きく</strong>なります。</p>\n<p>つまり、顔の向きや顔の輪郭などの大きな特徴は低解像度の際に、目の色など小さな特徴については高解像度の際にStyleとして適用されるのです。</p>\n<p>Styleの形で特徴を細かく分割し、Mixing Regularizationでそれぞれの特徴にあった変化を生み出すことができるようになったことがStyleGANのすばらしさと私は理解してます。</p>\n<h2 id=\"慣れない解説はもうやらない本題に戻ります\" style=\"position:relative;\"><a href=\"#%E6%85%A3%E3%82%8C%E3%81%AA%E3%81%84%E8%A7%A3%E8%AA%AC%E3%81%AF%E3%82%82%E3%81%86%E3%82%84%E3%82%89%E3%81%AA%E3%81%84%E6%9C%AC%E9%A1%8C%E3%81%AB%E6%88%BB%E3%82%8A%E3%81%BE%E3%81%99\" aria-label=\"慣れない解説はもうやらない本題に戻ります permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>慣れない解説はもうやらない、本題に戻ります</h2>\n<p>ごほん！</p>\n<p>当然、高解像度のGANは演算量は増えるので莫大な時間とお金(GPU)が必要になります。</p>\n<p>「子どもに学習学習っていいたくないですよね...。NVIDIAだからできたこと。(激寒)」</p>\n<p>私はNVIDIAではないのでモンスターGPUを大量に購入するお金ないですので今回は学習済みのモデルを借りて実験してみます。</p>\n<h2 id=\"making-anime-faces-with-stylegan\" style=\"position:relative;\"><a href=\"#making-anime-faces-with-stylegan\" aria-label=\"making anime faces with stylegan permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Making Anime Faces With StyleGAN</h2>\n<p>美少女キャラ生成用の学習済みモデルってないかなーと探してたら、ありました。</p>\n<p><a href=\"https://www.gwern.net/Faces\" target=\"_blank\" rel=\"noopener noreferrer\">Making Anime Faces With StyleGAN\n</a></p>\n<p><strong>gwern.net</strong>さんありがとうございます!!!！</p>\n<p>モデルは<a href=\"https://www.gwern.net/Faces#anime-faces\" target=\"_blank\" rel=\"noopener noreferrer\">StyleGAN model used for TWDNEv1 sample</a>からダウンロードできます。</p>\n<p><strong>ありがたくダウンロードしましょう。</strong></p>\n<p>感謝の気持ちで肩たたきけんを進呈します。</p>\n<p><img class=\"lozad\" src=\"data:image/gif;base64,R0lGODlhAQABAGAAACH5BAEKAP8ALAAAAAABAAEAAAgEAP8FBAA7\" data-src=\"https://i.imgur.com/0IEMnPa.png\" alt=\"img\"></p>\n<h2 id=\"styleganを使ってみる\" style=\"position:relative;\"><a href=\"#stylegan%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6%E3%81%BF%E3%82%8B\" aria-label=\"styleganを使ってみる permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>StyleGANを使ってみる</h2>\n<p>ダウンロードしたら早速使ってみます。StyleGANのソース(ライブラリ)はNVIDIAのGitHubに公開されてます。</p>\n<p><a href=\"https://github.com/NVlabs/stylegan\" target=\"_blank\" rel=\"noopener noreferrer\">NVlabs/stylegan</a></p>\n<p>学習はしないですが、推論のためにdnnlibを拝借するためソースをローカルにcloneします。</p>\n<p>また、事前にCUDAとTensorflowGPUを設定しておきます。</p>\n<p>環境差分が大きい話なので設定方法は各自ググってください.......。</p>\n<p>結構バージョンとかで苦戦しますので<a href=\"https://qiita.com/chin_self_driving_car/items/f00af2dbd022b65c9068\" target=\"_blank\" rel=\"noopener noreferrer\">こちら</a>を参考に設定しましょう。</p>\n<p>私の環境は下記で行いました。</p>\n<table>\n<thead>\n<tr>\n<th>key</th>\n<th>value</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>OS</td>\n<td>Windows10</td>\n</tr>\n<tr>\n<td>GPU</td>\n<td>NVIDIA GeForce RTX 2080</td>\n</tr>\n<tr>\n<td>CUDA</td>\n<td>10.0.0</td>\n</tr>\n<tr>\n<td>Python</td>\n<td>3.7.3</td>\n</tr>\n<tr>\n<td>tensorflow-gpu</td>\n<td>1.14.0</td>\n</tr>\n<tr>\n<td>numpy</td>\n<td>1.18.1</td>\n</tr>\n</tbody>\n</table>\n<p>ソースに同梱されている<strong>pretrained_example.py</strong>はNVIDIAが作ったモデルを用いて推論をしてみるスクリプトですがとりあえず、こちらを改造して画像生成用スクリプトを作ります。</p>\n<p>pretrained_example.pyではGoogle DriveからNVIDIA作成のモデルをダウンロードしますが、今回はAnimeFace用のモデルを使いたいので少しコードを変更します。</p>\n<p>ちなみにStyleGANのモデルはPickelファイル形式なので普通にPythonでバイナリオープンできます。</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">\n<span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> pickle\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">import</span> PIL<span class=\"token punctuation\">.</span>Image\n<span class=\"token keyword\">import</span> dnnlib\n<span class=\"token keyword\">import</span> dnnlib<span class=\"token punctuation\">.</span>tflib <span class=\"token keyword\">as</span> tflib\n<span class=\"token keyword\">import</span> config\n<span class=\"token keyword\">from</span> datetime <span class=\"token keyword\">import</span> datetime\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\"># Initialize TensorFlow.</span>\n    tflib<span class=\"token punctuation\">.</span>init_tf<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># ダウンロードしたpickelファイルを指定</span>\n    <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"2019-02-26-stylegan-faces-network-02048-016041.pkl\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"rb\"</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> f<span class=\"token punctuation\">:</span>\n        _<span class=\"token punctuation\">,</span> _<span class=\"token punctuation\">,</span> Gs <span class=\"token operator\">=</span> pickle<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span>f<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># Print network details.</span>\n    Gs<span class=\"token punctuation\">.</span>print_layers<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># Pick latent vector.</span>\n    <span class=\"token comment\"># 潜在変数を作成</span>\n    rnd <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>RandomState<span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span>\n    latents <span class=\"token operator\">=</span> rnd<span class=\"token punctuation\">.</span>randn<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> Gs<span class=\"token punctuation\">.</span>input_shape<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># Generate image.</span>\n    fmt <span class=\"token operator\">=</span> <span class=\"token builtin\">dict</span><span class=\"token punctuation\">(</span>func<span class=\"token operator\">=</span>tflib<span class=\"token punctuation\">.</span>convert_images_to_uint8<span class=\"token punctuation\">,</span> nchw_to_nhwc<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    images <span class=\"token operator\">=</span> Gs<span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span>latents<span class=\"token punctuation\">,</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> truncation_psi<span class=\"token operator\">=</span><span class=\"token number\">0.7</span><span class=\"token punctuation\">,</span> randomize_noise<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> output_transform<span class=\"token operator\">=</span>fmt<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># Save image.</span>\n    os<span class=\"token punctuation\">.</span>makedirs<span class=\"token punctuation\">(</span>config<span class=\"token punctuation\">.</span>result_dir<span class=\"token punctuation\">,</span> exist_ok<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    filename <span class=\"token operator\">=</span> datetime<span class=\"token punctuation\">.</span>now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>strftime<span class=\"token punctuation\">(</span><span class=\"token string\">'%Y%m%d%H%M%S'</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token string\">'.png'</span>\n    png_filename <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>config<span class=\"token punctuation\">.</span>result_dir<span class=\"token punctuation\">,</span> filename<span class=\"token punctuation\">)</span>\n    PIL<span class=\"token punctuation\">.</span>Image<span class=\"token punctuation\">.</span>fromarray<span class=\"token punctuation\">(</span>images<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'RGB'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span>png_filename<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">if</span> __name__ <span class=\"token operator\">==</span> <span class=\"token string\">\"__main__\"</span><span class=\"token punctuation\">:</span>\n    main<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n</code></pre></div>\n<p>うまくいけばresultsディレクトリに画像が生成されるはずです。</p>\n<p><img class=\"lozad\" src=\"data:image/gif;base64,R0lGODlhAQABAGAAACH5BAEKAP8ALAAAAAABAAEAAAgEAP8FBAA7\" data-src=\"https://i.imgur.com/ET5Bn63.png\" alt=\"img\"></p>\n<p><strong>あらかわ！</strong></p>\n<h2 id=\"aからbに画像を遷移transitionさせる\" style=\"position:relative;\"><a href=\"#a%E3%81%8B%E3%82%89b%E3%81%AB%E7%94%BB%E5%83%8F%E3%82%92%E9%81%B7%E7%A7%BBtransition%E3%81%95%E3%81%9B%E3%82%8B\" aria-label=\"aからbに画像を遷移transitionさせる permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>AからBに画像を遷移(Transition)させる</h2>\n<p>さらにちょっと頑張ってみましょう。</p>\n<p>生成した画像Aを少しずつ変化させて画像Bに変化させてみます。</p>\n<p>StyleGANはこのAからBへの遷移(Transition)も比較的きれいにできることが知られています。</p>\n<p>pretrained_example.pyとは異なりあらかじめ潜在変数の作成する画像枚数分ベクトルを生成してn => n+1の変化量をm分割する感じにする必要があります。</p>\n<p>こちらは<a href=\"https://blog.blacktanktop.me/?post=20191110_animation_stylegan\" target=\"_blank\" rel=\"noopener noreferrer\">イラストで学習したStyleGANを試した</a>を参考にしました。</p>\n<p>ファイル名は、<strong>generate_anime.py</strong>とします。</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> pickle\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">import</span> PIL<span class=\"token punctuation\">.</span>Image\n<span class=\"token keyword\">import</span> dnnlib<span class=\"token punctuation\">.</span>tflib <span class=\"token keyword\">as</span> tflib\n<span class=\"token keyword\">import</span> config\n<span class=\"token keyword\">from</span> datetime <span class=\"token keyword\">import</span> datetime\n\nFILENAME_PREFIX <span class=\"token operator\">=</span> datetime<span class=\"token punctuation\">.</span>now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>strftime<span class=\"token punctuation\">(</span><span class=\"token string\">\"%Y%m%d%H%M%S\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">generate_image</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"Generate GAN Image \"\"\"</span>\n    <span class=\"token comment\"># Initialize TensorFlow.</span>\n    tflib<span class=\"token punctuation\">.</span>init_tf<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># ダウンロードしたpickelファイルを指定</span>\n    <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"2019-02-26-stylegan-faces-network-02048-016041.pkl\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"rb\"</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> f<span class=\"token punctuation\">:</span>\n        _<span class=\"token punctuation\">,</span> _<span class=\"token punctuation\">,</span> Gs <span class=\"token operator\">=</span> pickle<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span>f<span class=\"token punctuation\">)</span>\n        <span class=\"token comment\"># Gs = Long-term average of the generator. Yields higher-quality results than the instantaneous snapshot.</span>\n\n    <span class=\"token comment\"># Print network details.</span>\n    Gs<span class=\"token punctuation\">.</span>print_layers<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># Pick latent vector.</span>\n    rnd <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>RandomState<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># 生成する画像枚数分、潜在変数を作っておく。ここでは30枚作成</span>\n    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">30</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        latents <span class=\"token operator\">=</span> rnd<span class=\"token punctuation\">.</span>randn<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> Gs<span class=\"token punctuation\">.</span>input_shape<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> i <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n            stacked_latents <span class=\"token operator\">=</span> latents\n        <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n            stacked_latents <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>vstack<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>stacked_latents<span class=\"token punctuation\">,</span> latents<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># AからBに遷移する画像を生成</span>\n    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>stacked_latents<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\"># before(A), after(B)をそれぞれ作る</span>\n        latents_before <span class=\"token operator\">=</span> stacked_latents<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        latents_after <span class=\"token operator\">=</span> stacked_latents<span class=\"token punctuation\">[</span>i <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">for</span> j <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">19</span> <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token comment\"># Aから19分割で少しずつBに潜在変数を変化</span>\n            latents <span class=\"token operator\">=</span> latents_before <span class=\"token operator\">+</span> <span class=\"token punctuation\">(</span>latents_after <span class=\"token operator\">-</span> latents_before<span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> j <span class=\"token operator\">/</span> <span class=\"token number\">19</span>\n            fmt <span class=\"token operator\">=</span> <span class=\"token builtin\">dict</span><span class=\"token punctuation\">(</span>func<span class=\"token operator\">=</span>tflib<span class=\"token punctuation\">.</span>convert_images_to_uint8<span class=\"token punctuation\">,</span> nchw_to_nhwc<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n            images <span class=\"token operator\">=</span> Gs<span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span>latents<span class=\"token punctuation\">,</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> truncation_psi<span class=\"token operator\">=</span><span class=\"token number\">0.7</span><span class=\"token punctuation\">,</span> randomize_noise<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> output_transform<span class=\"token operator\">=</span>fmt<span class=\"token punctuation\">)</span>\n            os<span class=\"token punctuation\">.</span>makedirs<span class=\"token punctuation\">(</span>config<span class=\"token punctuation\">.</span>result_dir<span class=\"token punctuation\">,</span> exist_ok<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n            <span class=\"token comment\"># MP4化したいのでファイルを連番になるように出力</span>\n            png_filename <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>config<span class=\"token punctuation\">.</span>result_dir<span class=\"token punctuation\">,</span> FILENAME_PREFIX <span class=\"token operator\">+</span> <span class=\"token string\">\"-{0:04d}-{1:04d}\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">,</span> j <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token string\">\".png\"</span><span class=\"token punctuation\">)</span>\n            PIL<span class=\"token punctuation\">.</span>Image<span class=\"token punctuation\">.</span>fromarray<span class=\"token punctuation\">(</span>images<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'RGB'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span>png_filename<span class=\"token punctuation\">)</span>\n\n\n<span class=\"token keyword\">if</span> __name__ <span class=\"token operator\">==</span> <span class=\"token string\">\"__main__\"</span><span class=\"token punctuation\">:</span>\n    generate_image<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>生成した画像をMP4にするとこんな感じになりました！</p>\n<iframe loading=\"lazy\" width=\"200\" height=\"150\" src=\"https://www.youtube.com/embed/VAAm-Ne3T6Y?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"StyleGAN AnimeFace\"></iframe>\n<p>おおー！すごい！なかなかしっかりしてますね。512x512の高解像度美少女キャラが無限増殖してます！</p>\n<p>StyleGANで美少女無限増殖は成功といってもいいのではないでしょうか!!</p>\n<h2 id=\"stylegan2でも美少女無限増殖\" style=\"position:relative;\"><a href=\"#stylegan2%E3%81%A7%E3%82%82%E7%BE%8E%E5%B0%91%E5%A5%B3%E7%84%A1%E9%99%90%E5%A2%97%E6%AE%96\" aria-label=\"stylegan2でも美少女無限増殖 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>StyleGAN2でも美少女無限増殖</h2>\n<p>StyleGANで成功をおさめたNVIDIAですがまだ歩みを止めません。StyleGANで出てきた課題を解決するべく、<a href=\"https://arxiv.org/abs/1912.04958\" target=\"_blank\" rel=\"noopener noreferrer\">StyleGAN2</a>を作りました。</p>\n<p>StyleGANとどう変わったかというのはもう難しいので専門の方に任せちゃいますがちらっとだけ解説すると、</p>\n<p>StyleGANで課題になった、</p>\n<ul>\n<li>水滴ノイズ(droplet)</li>\n<li>歯や目などの小さい特徴が顔の向きと連動しない(不自然モード)</li>\n</ul>\n<p>という問題を解消しています。</p>\n<p>さて、**StyleGAN2でも美少女キャラ無限増殖したい！**と心の声が聞こえてきますね。</p>\n<p>なんとStyleGAN2でも<strong>gwern.net</strong>さんがモデルを公開してくれてます！</p>\n<p><a href=\"https://www.gwern.net/Faces#stylegan-2\" target=\"_blank\" rel=\"noopener noreferrer\">Making Anime Faces With StyleGAN StyleGAN 2</a></p>\n<p>ありがたくこちらも使わせていただきます。</p>\n<p>また、StyleGAN2自体のソース(ライブラリ)はStyleGANと同じくGitHubに公開されています。</p>\n<p><a href=\"https://github.com/NVlabs/stylegan2\" target=\"_blank\" rel=\"noopener noreferrer\">NVlabs/stylegan2</a></p>\n<p>こちらをCloneして準備完了です。</p>\n<p>基本的にはStyleGAN2もStyleGANっぽくコーディングできるだろうと思い、先ほどの<strong>generate_anime.py</strong>を流用します。</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> pickle\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">import</span> PIL<span class=\"token punctuation\">.</span>Image\n<span class=\"token keyword\">import</span> dnnlib<span class=\"token punctuation\">.</span>tflib <span class=\"token keyword\">as</span> tflib\n<span class=\"token keyword\">from</span> datetime <span class=\"token keyword\">import</span> datetime\n\n<span class=\"token comment\"># number of create StyleGAN image file</span>\nIMAGE_NUM <span class=\"token operator\">=</span> <span class=\"token number\">30</span>\n<span class=\"token comment\"># number of split frame two GAN files for changing image</span>\nSPLIT_NUM <span class=\"token operator\">=</span> <span class=\"token number\">19</span>\n<span class=\"token comment\"># image size</span>\nIMG_SIZE <span class=\"token operator\">=</span> <span class=\"token number\">512</span>\nFILENAME_PREFIX <span class=\"token operator\">=</span> datetime<span class=\"token punctuation\">.</span>now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>strftime<span class=\"token punctuation\">(</span><span class=\"token string\">\"%Y%m%d%H%M%S\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">generate_image</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"Generate GAN Image \"\"\"</span>\n    <span class=\"token comment\"># Initialize TensorFlow.</span>\n    tflib<span class=\"token punctuation\">.</span>init_tf<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># 2020-01-11-skylion-stylegan2-animeportraits-networksnapshot-024664.pkl (https://www.gwern.net/Faces#stylegan-2)</span>\n    <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"2020-01-11-skylion-stylegan2-animeportraits-networksnapshot-024664.pkl\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"rb\"</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> f<span class=\"token punctuation\">:</span>\n        _<span class=\"token punctuation\">,</span> _<span class=\"token punctuation\">,</span> Gs <span class=\"token operator\">=</span> pickle<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span>f<span class=\"token punctuation\">)</span>\n        <span class=\"token comment\"># Gs = Long-term average of the generator. Yields higher-quality results than the instantaneous snapshot.</span>\n\n    <span class=\"token comment\"># Print network details.</span>\n    Gs<span class=\"token punctuation\">.</span>print_layers<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># Pick latent vector.</span>\n    rnd <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>RandomState<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># create latents stacks because of changing several latents vectors.</span>\n    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>IMAGE_NUM<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        latents <span class=\"token operator\">=</span> rnd<span class=\"token punctuation\">.</span>randn<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> Gs<span class=\"token punctuation\">.</span>input_shape<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> i <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n            stacked_latents <span class=\"token operator\">=</span> latents\n        <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n            stacked_latents <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>vstack<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>stacked_latents<span class=\"token punctuation\">,</span> latents<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>stacked_latents<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        latents_before <span class=\"token operator\">=</span> stacked_latents<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        latents_after <span class=\"token operator\">=</span> stacked_latents<span class=\"token punctuation\">[</span>i <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">for</span> j <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>SPLIT_NUM <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            latents <span class=\"token operator\">=</span> latents_before <span class=\"token operator\">+</span> <span class=\"token punctuation\">(</span>latents_after <span class=\"token operator\">-</span> latents_before<span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> j <span class=\"token operator\">/</span> SPLIT_NUM\n            fmt <span class=\"token operator\">=</span> <span class=\"token builtin\">dict</span><span class=\"token punctuation\">(</span>func<span class=\"token operator\">=</span>tflib<span class=\"token punctuation\">.</span>convert_images_to_uint8<span class=\"token punctuation\">,</span> nchw_to_nhwc<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n            images <span class=\"token operator\">=</span> Gs<span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span>latents<span class=\"token punctuation\">,</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> truncation_psi<span class=\"token operator\">=</span><span class=\"token number\">0.7</span><span class=\"token punctuation\">,</span> randomize_noise<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> output_transform<span class=\"token operator\">=</span>fmt<span class=\"token punctuation\">)</span>\n            os<span class=\"token punctuation\">.</span>makedirs<span class=\"token punctuation\">(</span><span class=\"token string\">\"results\"</span><span class=\"token punctuation\">,</span> exist_ok<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n            png_filename <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span><span class=\"token string\">\"results\"</span><span class=\"token punctuation\">,</span> FILENAME_PREFIX <span class=\"token operator\">+</span> <span class=\"token string\">\"-{0:04d}-{1:04d}\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">,</span> j <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token string\">\".png\"</span><span class=\"token punctuation\">)</span>\n            PIL<span class=\"token punctuation\">.</span>Image<span class=\"token punctuation\">.</span>fromarray<span class=\"token punctuation\">(</span>images<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'RGB'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span>png_filename<span class=\"token punctuation\">)</span>\n\n\n\n<span class=\"token keyword\">if</span> __name__ <span class=\"token operator\">==</span> <span class=\"token string\">\"__main__\"</span><span class=\"token punctuation\">:</span>\n    generate_image<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n</code></pre></div>\n<p>1点コードを変更したところとしてはStyleGAN2のdnnlibに<strong>config</strong>がないのでresultsディレクトリの指定は文字列で行います。</p>\n<p>さあ！実行しますわよー！</p>\n<h3 id=\"おや動かない\" style=\"position:relative;\"><a href=\"#%E3%81%8A%E3%82%84%E5%8B%95%E3%81%8B%E3%81%AA%E3%81%84\" aria-label=\"おや動かない permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>おや!?動かない。</h3>\n<p>まぁそう簡単にはいきませんね。エラーを吐いて落ちてしまいました。</p>\n<p>エラーメッセージ↓</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Setting up TensorFlow plugin \"fused_bias_act.cu\": Preprocessing... Failed!\nTraceback (most recent call last):\n  File \"generate_anime.py\", line 75, in &lt;module>\n    generate_image()\n  File \"generate_anime.py\", line 27, in generate_image\n    _, _, Gs = pickle.load(f)\n  File \"E:\\tubone\\project\\stylegan2\\dnnlib\\tflib\\network.py\", line 297, in __setstate__\n    self._init_graph()\n  File \"E:\\tubone\\project\\stylegan2\\dnnlib\\tflib\\network.py\", line 154, in _init_graph\n    out_expr = self._build_func(*self.input_templates, **build_kwargs)\n  File \"&lt;string>\", line 491, in G_synthesis_stylegan2\n  File \"&lt;string>\", line 455, in layer\n  File \"&lt;string>\", line 99, in modulated_conv2d_layer\n  File \"&lt;string>\", line 68, in apply_bias_act\n  File \"E:\\tubone\\project\\stylegan2\\dnnlib\\tflib\\ops\\fused_bias_act.py\", line 68, in fused_bias_act\n    return impl_dict[impl](x=x, b=b, axis=axis, act=act, alpha=alpha, gain=gain)\n  File \"E:\\tubone\\project\\stylegan2\\dnnlib\\tflib\\ops\\fused_bias_act.py\", line 122, in _fused_bias_act_cuda\n    cuda_kernel = _get_plugin().fused_bias_act\n  File \"E:\\tubone\\project\\stylegan2\\dnnlib\\tflib\\ops\\fused_bias_act.py\", line 16, in _get_plugin\n    return custom_ops.get_plugin(os.path.splitext(__file__)[0] + '.cu')\n  File \"E:\\tubone\\project\\stylegan2\\dnnlib\\tflib\\custom_ops.py\", line 111, in get_plugin\n    _run_cmd(_prepare_nvcc_cli('\"%s\" --preprocess -o \"%s\" --keep --keep-dir \"%s\"' % (cuda_file, tmp_file, tmp_dir)))\n  File \"E:\\tubone\\project\\stylegan2\\dnnlib\\tflib\\custom_ops.py\", line 76, in _prepare_nvcc_cli\n    raise RuntimeError('Could not find MSVC/GCC/CLANG installation on this computer. Check compiler_bindir_search_path list in \"%s\".' % __file__)\nRuntimeError: Could not find MSVC/GCC/CLANG installation on this computer. Check compiler_bindir_search_path list in \"E:\\tubone\\project\\stylegan2\\dnnlib\\tflib\\custom_ops.py\".</code></pre></div>\n<p>エラーメッセージ抜粋↓</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">RuntimeError: Could not find MSVC/GCC/CLANG installation on this computer. Check compiler_bindir_search_path list in \"E:\\tubone\\project\\stylegan2\\dnnlib\\tflib\\custom_ops.py\".</code></pre></div>\n<p>とのことです。<strong>MSVC/GCC/CLANG</strong>ということは<strong>VCかGCCのコンパイラが必要</strong>とのことです。</p>\n<p><strong>Windows10で実行しているのでVCが必要なんですね。</strong></p>\n<p>エラーを見て何のことかと思いましたが、StyleGAN2の<a href=\"https://github.com/NVlabs/stylegan2#requirements\" target=\"_blank\" rel=\"noopener noreferrer\">Requirements</a>に普通に書いてありました。</p>\n<p>見切り発車もいいところだ..。</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">On Windows, the compilation requires Microsoft Visual Studio to be in PATH. We recommend installing Visual Studio Community Edition and adding into PATH using \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Auxiliary\\Build\\vcvars64.bat\".</code></pre></div>\n<p>VCでのコンパイルが必要なんですねということはわかったのですが、釈然としません。</p>\n<p>なぜならもともとVisual Studio 2019は入れているからです。</p>\n<p>パスも通してます。当然VCのコンパイラも含まれているわけで。</p>\n<p>もう一度エラーメッセージを見返すと<strong>custom_ops.py</strong>を編集してねとのことなので確認します。</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># Copyright (c) 2019, NVIDIA Corporation. All rights reserved.</span>\n<span class=\"token comment\">#</span>\n<span class=\"token comment\"># This work is made available under the Nvidia Source Code License-NC.</span>\n<span class=\"token comment\"># To view a copy of this license, visit</span>\n<span class=\"token comment\"># https://nvlabs.github.io/stylegan2/license.html</span>\n\n<span class=\"token triple-quoted-string string\">\"\"\"TensorFlow custom ops builder.\n\"\"\"</span>\n\n<span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> re\n<span class=\"token keyword\">import</span> uuid\n<span class=\"token keyword\">import</span> hashlib\n<span class=\"token keyword\">import</span> tempfile\n<span class=\"token keyword\">import</span> shutil\n<span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>python<span class=\"token punctuation\">.</span>client <span class=\"token keyword\">import</span> device_lib <span class=\"token comment\"># pylint: disable=no-name-in-module</span>\n\n<span class=\"token comment\">#----------------------------------------------------------------------------</span>\n<span class=\"token comment\"># Global options.</span>\n\ncuda_cache_path <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>dirname<span class=\"token punctuation\">(</span>__file__<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'_cudacache'</span><span class=\"token punctuation\">)</span>\ncuda_cache_version_tag <span class=\"token operator\">=</span> <span class=\"token string\">'v1'</span>\ndo_not_hash_included_headers <span class=\"token operator\">=</span> <span class=\"token boolean\">False</span> <span class=\"token comment\"># Speed up compilation by assuming that headers included by the CUDA code never change. Unsafe!</span>\nverbose <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span> <span class=\"token comment\"># Print status messages to stdout.</span>\n\ncompiler_bindir_search_path <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>\n    <span class=\"token string\">'C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC/14.14.26428/bin/Hostx64/x64'</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">'C:/Program Files (x86)/Microsoft Visual Studio/2019/Community/VC/Tools/MSVC/14.23.28105/bin/Hostx64/x64'</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">'C:/Program Files (x86)/Microsoft Visual Studio 14.0/vc/bin'</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">]</span>\n\n<span class=\"token comment\">#----------------------------------------------------------------------------</span></code></pre></div>\n<p>なるほど、StyleGAN2で使うVCのコンパイラは<strong>compiler_bindir_search_path</strong>で設定しているんですね。</p>\n<p>確かにこちらが実環境とあっていませんでした。</p>\n<p>こちらを実環境に合わせて修正します。</p>\n<p>また、もう少しStyleGAN2のレポジトリを眺めたら、MSVCのチェックスクリプト<strong>test_nvcc.cu</strong>がGitHubのレポジトリに普通にありました...。</p>\n<p>どんだけ見切り発車なんだよ..。</p>\n<p>さて気を取り直して、Visual Studio 2019のパスを正しく書き直しtest_nvcc.cuを実行してみたところ、</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">(tensorflow) E:\\tubone\\project\\stylegan2>nvcc test_nvcc.cu -o test_nvcc -run\ntest_nvcc.cu\n\nC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\bin/../include\\cuda_runtime.h: warning C4819: ファイルは、現在 のコード ページ (932) で表示できない文字を含んでいます。データの損失を防ぐために、ファイルを Unicode 形式で保存してくだ さい。\nC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\include\\crt/host_config.h(143): fatal error C1189: #error:  -- unsupported Microsoft Visual Studio version! Only the versions between 2013 and 2017 (inclusive) are supported!</code></pre></div>\n<p>Warinigは置いておいて、<strong>fatal error</strong>が出てますね。なんだかVisual Stadio 2019に対応してないとか出てきた..。</p>\n<p>んー.... じゃあ2017いれますか..。</p>\n<p><a href=\"https://my.visualstudio.com/Downloads?q=visual%20studio%202017&#x26;wt.mc_id=o~msft~vscom~older-downloads\" target=\"_blank\" rel=\"noopener noreferrer\">こちら</a>からVisual Studio 2017をダウンロードしインストールします。</p>\n<p>もちろんMSVCが必要なのでちゃんとインストーラーでC++の開発はインストールしましょう！</p>\n<p>インストール後は<strong>compiler_bindir_search_path</strong>にパスを設定します。パスは<strong>cl.exe</strong>が存在する箇所です。バージョン名以外は<strong>custom_ops.py</strong>の通りで大丈夫だと思います。</p>\n<p>うまくパスを設定してないとtest_nvcc.cuを実行すると、</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">(tensorflow) E:\\tubone\\project\\stylegan2>nvcc test_nvcc.cu -o test_nvcc -run\nnvcc fatal   : Cannot find compiler 'cl.exe' in PATH</code></pre></div>\n<p>とcl.exeがPATHに見つからないと怒られます。</p>\n<p>私の環境のcl.exeは、</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\bin\\Hostx64\\x64</code></pre></div>\n<p>でした。</p>\n<p>うまくPATHを通してtest_nvcc.cuを実行すると...。</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">現在のコード ページ (932) で表示できない文字を含んでいます。データの損失を防ぐために、ファイルを Unicode 形式で保存して ください。\n   ライブラリ test_nvcc.lib とオブジェクト test_nvcc.exp を作成中\nCPU says hello.\nGPU says hello.</code></pre></div>\n<p>Unicode warinigはでるものの、</p>\n<p><strong>CPU says hello.</strong></p>\n<p><strong>GPU says hello.</strong></p>\n<p>と表示されました。「ハロー！」</p>\n<p>まったく関係ないですが、ハローといえば<strong>Radio Happy</strong>ですよね。好き。</p>\n<iframe loading=\"lazy\" width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/9pY9MrjeLD4?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"【アイドルマスター】「Radio Happy」(歌：大槻唯)\"></iframe>\n<p>よし！時はきた！</p>\n<p><strong>generate_anime.py</strong>を実行します。</p>\n<p><img class=\"lozad\" src=\"data:image/gif;base64,R0lGODlhAQABAGAAACH5BAEKAP8ALAAAAAABAAEAAAgEAP8FBAA7\" data-src=\"https://i.imgur.com/k3KihLx.png\" alt=\"img\"></p>\n<h3 id=\"まだうまく動かない\" style=\"position:relative;\"><a href=\"#%E3%81%BE%E3%81%A0%E3%81%86%E3%81%BE%E3%81%8F%E5%8B%95%E3%81%8B%E3%81%AA%E3%81%84\" aria-label=\"まだうまく動かない permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>まだうまく動かない</h3>\n<p>エラーがでました..。</p>\n<p><img class=\"lozad\" src=\"data:image/gif;base64,R0lGODlhAQABAGAAACH5BAEKAP8ALAAAAAABAAEAAAgEAP8FBAA7\" data-src=\"https://i.imgur.com/0KH7SgH.png\" alt=\"img\"></p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">RuntimeError: NVCC returned an error. See below for full command line and output log:\n\nnvcc \"C:\\Users\\meita\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\_pywrap_tensorflow_internal.lib\" --gpu-architecture=sm_75 --use_fast_math --disable-warnings --include-path \"C:\\Users\\meita\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\include\" --include-path \"C:\\Users\\meita\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\include\\external\\protobuf_archive\\src\" --include-path \"C:\\Users\\meita\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\include\\external\\com_google_absl\" --include-path \"C:\\Users\\meita\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\include\\external\\eigen_archive\" --compiler-bindir \"C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC/14.16.27023/bin/Hostx64/x64\" 2>&amp;1 \"C:\\Users\\meita\\Downloads\\stylegan2\\dnnlib\\tflib\\ops\\fused_bias_act.cu\" --shared -o \"C:\\Users\\meita\\AppData\\Local\\Temp\\tmp3_sgpk48\\fused_bias_act_tmp.dll\" --keep --keep-dir \"C:\\Users\\meita\\AppData\\Local\\Temp\\tmp3_sgpk48\"\n\n_pywrap_tensorflow_internal.lib\nfused_bias_act.cu\nnvcc error   : 'cudafe++' died with status 0xC0000005 (ACCESS_VIOLATION)</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">nvcc error   : 'cudafe++' died with status 0xC0000005 (ACCESS_VIOLATION)</code></pre></div>\n<p>とのことです。なんだこれ...。</p>\n<h3 id=\"nvcc-error--cudafe-died-with-status-0xc0000005-access_violation\" style=\"position:relative;\"><a href=\"#nvcc-error--cudafe-died-with-status-0xc0000005-access_violation\" aria-label=\"nvcc error  cudafe died with status 0xc0000005 access_violation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>nvcc error : 'cudafe++' died with status 0xC0000005 (ACCESS_VIOLATION)</h3>\n<p>ここまできて半分諦めてたのですが、ダメ元でエラーをググったらTensorflowに気になるIssueを発見しました。</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/issues/27706\" target=\"_blank\" rel=\"noopener noreferrer\">nvcc error : 'cudafe++' died with status 0xC0000005 (ACCESS_VIOLATION) #27706</a></p>\n<p><img class=\"lozad\" src=\"data:image/gif;base64,R0lGODlhAQABAGAAACH5BAEKAP8ALAAAAAABAAEAAAgEAP8FBAA7\" data-src=\"https://i.imgur.com/zXCnrTq.png\" alt=\"img\"></p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">You need to Install Visual C++ Build Tools 2015 Please take a look at these instructions.</code></pre></div>\n<p>はぁ... 2015ですか..。</p>\n<p>2017で動くって言ってたじゃないか！</p>\n<p><img class=\"lozad\" src=\"data:image/gif;base64,R0lGODlhAQABAGAAACH5BAEKAP8ALAAAAAABAAEAAAgEAP8FBAA7\" data-src=\"https://i.imgur.com/1KUffz4.png\" alt=\"img\"></p>\n<p>ということで<strong>Visual Studio 2015</strong>をインストールします..。</p>\n<p><a href=\"https://my.visualstudio.com/Downloads?q=visual%20studio%202015&#x26;wt.mc_id=o~msft~vscom~older-downloads\" target=\"_blank\" rel=\"noopener noreferrer\">https://my.visualstudio.com/Downloads?q=visual%20studio%202015&#x26;wt.mc_id=o~msft~vscom~older-downloads</a></p>\n<p>Visual Studio 2015は通常インストールするとVCインストールの項目がないのでインストール後、再度インストーラーを起動してVCをインストールするように修正します。</p>\n<p>何気に面倒だよねこれ、Stack overflow君が教えてくれなければ解決できなかったよぉ。</p>\n<p><a href=\"https://stackoverflow.com/questions/31953769/visual-studio-2015-doesnt-have-cl-exe\" target=\"_blank\" rel=\"noopener noreferrer\">Visual Studio 2015 doesn't have cl.exe</a></p>\n<h3 id=\"3度目の正直\" style=\"position:relative;\"><a href=\"#3%E5%BA%A6%E7%9B%AE%E3%81%AE%E6%AD%A3%E7%9B%B4\" aria-label=\"3度目の正直 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3度目の正直</h3>\n<p>よし！適当)</p>\n<p><strong>generate_anime.py</strong>実行します！</p>\n<p><img class=\"lozad\" src=\"data:image/gif;base64,R0lGODlhAQABAGAAACH5BAEKAP8ALAAAAAABAAEAAAgEAP8FBAA7\" data-src=\"https://i.imgur.com/YE8Pdyb.png\" alt=\"img\"></p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">(tensorflow) E:\\tubone\\project\\stylegan2>python generate_anime.py\nC:\\Users\\meita\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\nC:\\Users\\meita\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\nC:\\Users\\meita\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\nC:\\Users\\meita\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\nC:\\Users\\meita\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\nC:\\Users\\meita\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\nC:\\Users\\meita\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\nC:\\Users\\meita\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\nC:\\Users\\meita\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\nC:\\Users\\meita\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\nC:\\Users\\meita\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\nC:\\Users\\meita\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\nSetting up TensorFlow plugin \"fused_bias_act.cu\": Preprocessing... Loading... Done.\nSetting up TensorFlow plugin \"upfirdn_2d.cu\": Preprocessing... Loading... Done.\n\nGs                            Params    OutputShape         WeightShape\n---                           ---       ---                 ---\nlatents_in                    -         (?, 512)            -\nlabels_in                     -         (?, 0)              -\nlod                           -         ()                  -\ndlatent_avg                   -         (512,)              -\nG_mapping/latents_in          -         (?, 512)            -\nG_mapping/labels_in           -         (?, 0)              -\nG_mapping/Normalize           -         (?, 512)            -\nG_mapping/Dense0              262656    (?, 512)            (512, 512)\nG_mapping/Dense1              262656    (?, 512)            (512, 512)\nG_mapping/Dense2              262656    (?, 512)            (512, 512)\nG_mapping/Dense3              262656    (?, 512)            (512, 512)\nG_mapping/Dense4              262656    (?, 512)            (512, 512)\nG_mapping/Dense5              262656    (?, 512)            (512, 512)\nG_mapping/Dense6              262656    (?, 512)            (512, 512)\nG_mapping/Dense7              262656    (?, 512)            (512, 512)\nG_mapping/Broadcast           -         (?, 16, 512)        -\nG_mapping/dlatents_out        -         (?, 16, 512)        -\nTruncation/Lerp               -         (?, 16, 512)        -\nG_synthesis/dlatents_in       -         (?, 16, 512)        -\nG_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)\nG_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\nG_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)\nG_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\nG_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\nG_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -\nG_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)\nG_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\nG_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\nG_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -\nG_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)\nG_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\nG_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\nG_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -\nG_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)\nG_synthesis/64x64/Conv0_up    2622465   (?, 512, 64, 64)    (3, 3, 512, 512)\nG_synthesis/64x64/Conv1       2622465   (?, 512, 64, 64)    (3, 3, 512, 512)\nG_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -\nG_synthesis/64x64/ToRGB       264195    (?, 3, 64, 64)      (1, 1, 512, 3)\nG_synthesis/128x128/Conv0_up  1442561   (?, 256, 128, 128)  (3, 3, 512, 256)\nG_synthesis/128x128/Conv1     721409    (?, 256, 128, 128)  (3, 3, 256, 256)\nG_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -\nG_synthesis/128x128/ToRGB     132099    (?, 3, 128, 128)    (1, 1, 256, 3)\nG_synthesis/256x256/Conv0_up  426369    (?, 128, 256, 256)  (3, 3, 256, 128)\nG_synthesis/256x256/Conv1     213249    (?, 128, 256, 256)  (3, 3, 128, 128)\nG_synthesis/256x256/Upsample  -         (?, 3, 256, 256)    -\nG_synthesis/256x256/ToRGB     66051     (?, 3, 256, 256)    (1, 1, 128, 3)\nG_synthesis/512x512/Conv0_up  139457    (?, 64, 512, 512)   (3, 3, 128, 64)\nG_synthesis/512x512/Conv1     69761     (?, 64, 512, 512)   (3, 3, 64, 64)\nG_synthesis/512x512/Upsample  -         (?, 3, 512, 512)    -\nG_synthesis/512x512/ToRGB     33027     (?, 3, 512, 512)    (1, 1, 64, 3)\nG_synthesis/images_out        -         (?, 3, 512, 512)    -\nG_synthesis/noise0            -         (1, 1, 4, 4)        -\nG_synthesis/noise1            -         (1, 1, 8, 8)        -\nG_synthesis/noise2            -         (1, 1, 8, 8)        -\nG_synthesis/noise3            -         (1, 1, 16, 16)      -\nG_synthesis/noise4            -         (1, 1, 16, 16)      -\nG_synthesis/noise5            -         (1, 1, 32, 32)      -\nG_synthesis/noise6            -         (1, 1, 32, 32)      -\nG_synthesis/noise7            -         (1, 1, 64, 64)      -\nG_synthesis/noise8            -         (1, 1, 64, 64)      -\nG_synthesis/noise9            -         (1, 1, 128, 128)    -\nG_synthesis/noise10           -         (1, 1, 128, 128)    -\nG_synthesis/noise11           -         (1, 1, 256, 256)    -\nG_synthesis/noise12           -         (1, 1, 256, 256)    -\nG_synthesis/noise13           -         (1, 1, 512, 512)    -\nG_synthesis/noise14           -         (1, 1, 512, 512)    -\nimages_out                    -         (?, 3, 512, 512)    -\n---                           ---       ---                 ---\nTotal                         30276583\n\n2020-05-04 03:03:32.366467: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were availa\nble.\n2020-05-04 03:03:32.377471: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were availa\nble.\n2020-05-04 03:03:32.966211: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.25GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were availa\nble.\n2020-05-04 03:03:32.976815: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.25GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were availa\nble.</code></pre></div>\n<p>実行できた!!</p>\n<p><img class=\"lozad\" src=\"data:image/gif;base64,R0lGODlhAQABAGAAACH5BAEKAP8ALAAAAAABAAEAAAgEAP8FBAA7\" data-src=\"https://i.imgur.com/daSYwz2.png\" alt=\"img\"></p>\n<p>ちゃんとresultsに画像が出力されてます！</p>\n<p><img class=\"lozad\" src=\"data:image/gif;base64,R0lGODlhAQABAGAAACH5BAEKAP8ALAAAAAABAAEAAAgEAP8FBAA7\" data-src=\"https://i.imgur.com/VfRjfpW.png\" alt=\"img\"></p>\n<p><strong>かわいいいいいい!!</strong></p>\n<p>小早川紗枝はんに似てますなー！</p>\n<p>紗枝はんといえばやっぱり<strong>美に入り彩を穿つ</strong>ですよね。</p>\n<iframe loading=\"lazy\" width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/96rmz41v6QE?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"「デレステ」美に入り彩を穿つ (Game ver.) 小早川紗枝、塩見周子 限定 SSR\"></iframe>\n<p>ごほん！</p>\n<p>ちゃんとTransitionもうまく出力されているようです！</p>\n<iframe loading=\"lazy\" width=\"200\" height=\"150\" src=\"https://www.youtube.com/embed/KpjWeNB5TUI?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"Style GAN2 animeface\"></iframe>\n<h2 id=\"結論\" style=\"position:relative;\"><a href=\"#%E7%B5%90%E8%AB%96\" aria-label=\"結論 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>結論</h2>\n<p>ここまでのスクリプトはNVIDIAのStyleGAN, StyleGAN2をForkした形でGitHubにおいてます。</p>\n<p><a href=\"https://github.com/tubone24/stylegan\" target=\"_blank\" rel=\"noopener noreferrer\">https://github.com/tubone24/stylegan</a></p>\n<p><a href=\"https://github.com/tubone24/stylegan2\" target=\"_blank\" rel=\"noopener noreferrer\">https://github.com/tubone24/stylegan2</a></p>\n<p>機械学習特有の環境構築とかで躓くあるあるはあるものの、何とかできました。</p>\n<p>また、GANの世界もここまで進化していると知りびっくりしました。</p>\n<p>次回はこちらをJetson nanoに移植していきたいと思います。</p>\n<h2 id=\"参考\" style=\"position:relative;\"><a href=\"#%E5%8F%82%E8%80%83\" aria-label=\"参考 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>参考</h2>\n<ul>\n<li><a href=\"https://medium.com/@akichan_f/gan%E3%81%AE%E5%9F%BA%E7%A4%8E%E3%81%8B%E3%82%89stylegan2%E3%81%BE%E3%81%A7-dfd2608410b3\" target=\"_blank\" rel=\"noopener noreferrer\">GANの基礎からStyleGAN2まで</a></li>\n<li><a href=\"https://www.slideshare.net/KentoDoi/stylegan-cvpr2019dena\" target=\"_blank\" rel=\"noopener noreferrer\">StyleGAN解説 CVPR2019読み会@DeNA</a></li>\n<li><a href=\"https://blog.blacktanktop.me/?post=20191110_animation_stylegan\" target=\"_blank\" rel=\"noopener noreferrer\">イラストで学習したStyleGANを試した</a></li>\n<li><a href=\"https://qiita.com/chin_self_driving_car/items/f00af2dbd022b65c9068\" target=\"_blank\" rel=\"noopener noreferrer\">Tensorflow GPU, CUDA, CuDNNのバージョン早見表</a></li>\n</ul>","words":7695,"minutes":20}},"staticQueryHashes":["1319877725","2959249232"]}