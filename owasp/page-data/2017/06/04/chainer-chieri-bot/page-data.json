{"componentChunkName":"component---src-templates-blog-post-tsx","path":"/2017/06/04/chainer-chieri-bot","result":{"data":{"content":{"edges":[{"node":{"id":"2107d1b1-60df-5088-93c2-26b1dd27586e","excerpt":"(過去ブログからの移転した記事です) なるべくコードはかかない。 何の気なしに機械学習とかの仕事はないものかと、ネットの海をさまよっていたら、 LSTM…","fields":{"slug":"2017/06/04/chainer-chieri-bot"},"frontmatter":{"id":null,"title":"今更！！ Chainer 1.6.1 でおしゃべりBotを作ろう","slug":"2017/06/04/chainer-chieri-bot","date":"2017-06-04T02:45:59.982Z","headerImage":"https://i.imgur.com/DJL1fwu.png","tags":["Python","Chainer","RNN","LSTM","Chat BOT","アイマス","デレマス"]}}}]}},"pageContext":{"id":"2107d1b1-60df-5088-93c2-26b1dd27586e","index":105,"repHtml":"<p>(過去ブログからの移転した記事です)</p>\n<p>なるべくコードはかかない。</p>\n<p>何の気なしに機械学習とかの仕事はないものかと、ネットの海をさまよっていたら、</p>\n<p><a href=\"https://sekailab.com/wp/2015/11/02/lstm-general-responce-bot/\" target=\"_blank\" rel=\"noopener noreferrer\">LSTMで自然な受け答えができるボットをつくった</a> という記事を見つけ、何となく読んで、やってみようかなと思ってやってみましたが、Chianer周りとか色々上手くいかなかった。というのがそもそもの始まりです。</p>\n<p><strong>Chainer周りで日本語の受け答えができますよ</strong>、的な記事は<strong>2015年頃</strong>のものが多く、Chainerがバージョンアップしたため、色々動かないことがありましたので、少しそちらに修正を加えて<strong>Chainer 1.6.1</strong>でもまともに動くように修正していこうと思います。</p>\n<p>自分でコードを一から書くのは嫌なので、<strong>あくまでもコードは書かない。</strong></p>\n<p>微修正にとどめるをモットーにがんばるぞい。</p>\n<h2 id=\"table-of-contents\" style=\"position:relative;\"><a href=\"#table-of-contents\" aria-label=\"table of contents permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Table of Contents</h2>\n<div class=\"toc\">\n<ul>\n<li><a href=\"#%E5%8F%82%E8%80%83%E3%81%AB%E3%81%95%E3%81%9B%E3%81%A6%E3%81%84%E3%81%9F%E3%81%A0%E3%81%84%E3%81%9F%E3%82%B3%E3%83%BC%E3%83%89%E3%82%84%E3%82%B5%E3%82%A4%E3%83%88\">参考にさせていただいたコードやサイト</a></li>\n<li><a href=\"#%E3%82%B5%E3%83%BC%E3%83%90%E3%83%BC%E3%82%92%E7%94%A8%E6%84%8F%E3%81%99%E3%82%8B\">サーバーを用意する</a></li>\n<li><a href=\"#%E5%AD%A6%E7%BF%92%E3%81%AB%E5%BF%85%E8%A6%81%E3%81%AApython%E7%92%B0%E5%A2%83%E3%81%A8%E3%82%B3%E3%83%BC%E3%83%91%E3%82%B9%E3%82%92%E6%95%B4%E3%81%88%E3%82%8B\">学習に必要なPython環境とコーパスを整える</a></li>\n<li><a href=\"#%E5%AD%A6%E7%BF%92%E3%81%95%E3%81%9B%E3%82%8B\">学習させる</a></li>\n<li><a href=\"#api%E3%81%A7%E8%A9%B1%E3%81%99\">APIで話す</a></li>\n<li><a href=\"#%E4%BB%98%E5%B1%9E%E3%81%AEhubot-script%E3%81%A7%E9%81%8A%E3%82%93%E3%81%A7%E3%81%BF%E3%82%88%E3%81%86\">付属のHubot Scriptで遊んでみよう！</a></li>\n</ul>\n</div>\n<h2 id=\"参考にさせていただいたコードやサイト\" style=\"position:relative;\"><a href=\"#%E5%8F%82%E8%80%83%E3%81%AB%E3%81%95%E3%81%9B%E3%81%A6%E3%81%84%E3%81%9F%E3%81%A0%E3%81%84%E3%81%9F%E3%82%B3%E3%83%BC%E3%83%89%E3%82%84%E3%82%B5%E3%82%A4%E3%83%88\" aria-label=\"参考にさせていただいたコードやサイト permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>参考にさせていただいたコードやサイト</h2>\n<ul>\n<li>\n<p><a href=\"https://sekailab.com/wp/2015/11/02/lstm-general-responce-bot/\" target=\"_blank\" rel=\"noopener noreferrer\">LSTMで自然な受け答えができるボットをつくった</a></p>\n<ul>\n<li>このコードを元にあらかじめ作成したChainerモデルでおしゃべりBotに命を吹き込みます。</li>\n</ul>\n</li>\n<li>\n<p><a href=\"https://github.com/yusuketomoto/chainer-char-rnn\" target=\"_blank\" rel=\"noopener noreferrer\">yusuketomoto/chainer-char-rnn</a>　</p>\n<ul>\n<li>Chainer・日本語界隈では知らない人はいないだろうChainerの言語モデル作成コード。こちらを用いてChainerモデルを作成していきます。</li>\n</ul>\n</li>\n<li>\n<p><a href=\"https://qiita.com/GushiSnow/items/79ca7deeb976f50126d7\" target=\"_blank\" rel=\"noopener noreferrer\">Chainerで学習した対話用のボットをSlackで使用+Twitterから学習データを取得してファインチューニング</a></p>\n<ul>\n<li>学習に必要なコーパスを取得するために一部のスクリプトを使用します。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"サーバーを用意する\" style=\"position:relative;\"><a href=\"#%E3%82%B5%E3%83%BC%E3%83%90%E3%83%BC%E3%82%92%E7%94%A8%E6%84%8F%E3%81%99%E3%82%8B\" aria-label=\"サーバーを用意する permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>サーバーを用意する</h2>\n<p>学習にも、会話にも自宅サーバーを用います。</p>\n<p>ああ、電気代。</p>\n<h2 id=\"学習に必要なpython環境とコーパスを整える\" style=\"position:relative;\"><a href=\"#%E5%AD%A6%E7%BF%92%E3%81%AB%E5%BF%85%E8%A6%81%E3%81%AApython%E7%92%B0%E5%A2%83%E3%81%A8%E3%82%B3%E3%83%BC%E3%83%91%E3%82%B9%E3%82%92%E6%95%B4%E3%81%88%E3%82%8B\" aria-label=\"学習に必要なpython環境とコーパスを整える permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>学習に必要なPython環境とコーパスを整える</h2>\n<p>Chainer界隈のコードはなぜかPython2が多く、Python3は少ないので、直接Python2をインストールしてもいいのですが…。</p>\n<p>なんかOS環境を変に汚したくないので今回は<strong>PyenvとVirtualenv</strong>を使って実施していきます。</p>\n<p>学習用のコーパスをダウンロードするスクリプトはどうやら<strong>Python 3.4.1</strong>で実装されているようなので <strong>Python 3.4.1</strong> と <strong>Python2.7</strong> の2種類の環境を作っていきたいと思います。</p>\n<p>そして、3.4.1の環境にて学習用のコーパスをダウンロードします。</p>\n<p>PyenvとVirtualenvはあらかじめインストール済みとしてすすめます。</p>\n<p>PyenvとVirtualenvのインストール方法はこちらの記事が参考になると思います。<a href=\"https://qiita.com/Kodaira_/items/feadfef9add468e3a85b\" target=\"_blank\" rel=\"noopener noreferrer\">（pyenvとvirtualenvで環境構築）\n</a></p>\n<p>まず、Pythonの環境を作ります。</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ pyenv <span class=\"token function\">install</span> <span class=\"token number\">3.4</span>.1\n\n$ pyenv <span class=\"token function\">install</span> <span class=\"token number\">2.7</span>\n\n$ pyenv rehash\n\n$ virtualenv -p ~/.pyenv/versions/3.4.1/bin/python3.4 my_env3.4.1\n\n$ virtualenv -p ~/.pyenv/versions/2.7/bin/python2.7 my_env2.7</code></pre></div>\n<p>続いてコーパスをダウンロードします。</p>\n<p>今回は<a href=\"https://qiita.com/GushiSnow/items/79ca7deeb976f50126d7\" target=\"_blank\" rel=\"noopener noreferrer\">Chainerで学習した対話用のボットをSlackで使用+Twitterから学習データを取得してファインチューニング</a>を参考にダウンロードします。</p>\n<p>コーパスデータはたぶん二次配布とかNGだと思うので、何とか自分でダウンロードしてください。</p>\n<p><a href=\"https://sites.google.com/site/dialoguebreakdowndetection/\" target=\"_blank\" rel=\"noopener noreferrer\">対話破綻検出チャレンジ</a></p>\n<p>ダウンロードしたあとは展開したJSONデータ全部、devフォルダを作成してその中に入れて、listファイル(JSONファイルのパスを記載したやつ)をdata_load.pyと同じところに作っておきます。</p>\n<p>こんな感じでlistファイルを作ります。</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">../dev/1404365812.log.json\n../dev/1407143708.log.json\n../dev/1407143981.log.json\n../dev/1407149923.log.json\n../dev/1407208809.log.json\n../dev/1407209083.log.json\n…… </code></pre></div>\n<p>Linuxのコマンド(bash)で</p>\n<p><code class=\"language-text\">ls -1 ../dev > list</code></p>\n<p>で作成できるはず。</p>\n<p>学習データを作っていきます。</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token builtin class-name\">source</span> my_env3.4.1/bin/activate\n\n$ <span class=\"token function\">git</span> clone https://github.com/SnowMasaya/Chainer-Slack-Twitter-Dialogue.git\n\n$ <span class=\"token builtin class-name\">cd</span> chainer-slack-twitter/utils\n\n$ python data_load.py</code></pre></div>\n<p>player_1.txt , player_2.txtというテキストファイルができます。</p>\n<p>統合する前にmecabを使って分かち書きをしておきます。</p>\n<p>分かち書きに<strong>mecab-ipadic-NEologd</strong>を使うと学習が進むそうですので入れてないほうは導入しましょう。</p>\n<p>めんどくさい人はただの<strong>MeCab</strong>でも大丈夫だと思います。</p>\n<p>さて、分かち書きします。今回は <strong>mecab-ipadic-NEologd</strong> を利用します。</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">mecab –Owakati –d /usr/local/lib/mecab/dic/mecab–ipadic–neologd player_1.txt <span class=\"token operator\">></span> player_1_wakati.txt\n\nmecab –Owakati –d /usr/local/lib/mecab/dic/mecab–ipadic–neologd player_2.txt <span class=\"token operator\">></span> player_2_wakati.txt</code></pre></div>\n<p>次に使うChainer-char-rnn用に一つのinput.txtに統合していきます。統合の際に、player1とplayer2の会話ごとに空行を入れておきます。</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token function\">paste</span> -d “<span class=\"token punctuation\">\\</span>n” player_1_wakati.txt player_2_wakati.txt <span class=\"token operator\">|</span> <span class=\"token function\">awk</span> ‘<span class=\"token punctuation\">(</span>NR%2<span class=\"token operator\">==</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">{</span><span class=\"token variable\">$0</span><span class=\"token operator\">=</span><span class=\"token variable\">$0</span>″<span class=\"token punctuation\">\\</span>n”<span class=\"token punctuation\">}</span><span class=\"token punctuation\">{</span>print<span class=\"token punctuation\">}</span>’ <span class=\"token operator\">></span> input.txt</code></pre></div>\n<p>こちらのinput.txtをコーパスデータとして利用します。</p>\n<h2 id=\"学習させる\" style=\"position:relative;\"><a href=\"#%E5%AD%A6%E7%BF%92%E3%81%95%E3%81%9B%E3%82%8B\" aria-label=\"学習させる permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>学習させる</h2>\n<p>学習には<a href=\"https://github.com/yusuketomoto/chainer-char-rnn\" target=\"_blank\" rel=\"noopener noreferrer\">yusuketomoto/chainer-char-rnn</a>を使わせていただきます！</p>\n<p><strong>Chainer 1.4.1</strong> で実行しようとしたら微妙に実装が変わっていた用なので、こちらに合わせて今回の学習は、<strong>Chainer 1.6.1</strong> で実施していきます。(Chainer周りのコードを読んで修正するより、後に使うTornado周りの修正の方がまだわかるからというスキル不足によるもの)</p>\n<p>さきほど作っておいたPython 2.7用に切り替えます。PipでChainer1.6.1を入れてからChainer-char-rnnを実行していきます。</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token builtin class-name\">source</span> my_env2.7/bin/activate\n\n$ pip <span class=\"token function\">install</span> <span class=\"token assign-left variable\">chainer</span><span class=\"token operator\">==</span>”1.6.1″\n\n$ <span class=\"token function\">git</span> clone https://github.com/yusuketomoto/chainer-char-rnn.git\n\n$ <span class=\"token builtin class-name\">cd</span> chainer-char-rnn\n\n$ <span class=\"token function\">mkdir</span> -p data/chat\n\n$ <span class=\"token function\">mkdir</span> -p cv/chat\n\n$ <span class=\"token function\">cp</span> <span class=\"token punctuation\">..</span>/chainer-slack-twitter/input.txt data/chat\n\n$ python train.py –data_dir data/chat –checkpoint_dir cv/chat –rnn_size <span class=\"token number\">1024</span></code></pre></div>\n<p>しばらく待ちます。全部が終わるのは途方もない時間がかかります。</p>\n<p>学習が進むごとにCheckpointとしてChainer modelファイルがcv/chat配下にできますので、適当なEpochのところのものを次の「APIで話す」に使ってもいいですし、学習の最新ファイルである</p>\n<p>latest.chainermodelを使ってもいいです。もちろん、最後まで待ってからlatest.chainermodelを使ってもいいです。</p>\n<p>ひとまず数時間回したところのlatest.chainermodelを使ってみます。</p>\n<h2 id=\"apiで話す\" style=\"position:relative;\"><a href=\"#api%E3%81%A7%E8%A9%B1%E3%81%99\" aria-label=\"apiで話す permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>APIで話す</h2>\n<p><a href=\"https://sekailab.com/wp/2015/11/02/lstm-general-responce-bot/\" target=\"_blank\" rel=\"noopener noreferrer\">LSTMで自然な受け答えができるボットをつくった</a>よりJapanese Talk APIを作っていきます。</p>\n<p>この回では少々コードの改変がありますのでForkしたものをGitHubにあげました。</p>\n<p><a href=\"https://github.com/tubone24/japanese_talk_api_chainer14/tree/chainer1.6.1\" target=\"_blank\" rel=\"noopener noreferrer\">japanese_talk_api_1.6.1</a></p>\n<p>こちらのmodelsディレクトリにChainer modelを投入します。</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token function\">git</span> clone https://github.com/tubone24/japanese_talk_api/tree/chainer1.6.1.git\n\n$ <span class=\"token function\">mkdir</span> japanese_talk_api/tornado/models\n\n$ <span class=\"token function\">cp</span> chainer-char-rnn/cv/chat/latest.chainermodel japanese_talk_api/tornado/models</code></pre></div>\n<p>Chainerの他にTornadoも必要になるのでPipでインストールします。</p>\n<p>そしてAPIを8787ポートで起動します。</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ pip <span class=\"token function\">install</span> tornado\n\n$ python japanese_talk_api/tornado/app.py –port<span class=\"token operator\">=</span><span class=\"token number\">8787</span> –debug<span class=\"token operator\">=</span>True</code></pre></div>\n<p>あとは起動を待ってからcurlやブラウザなどで</p>\n<p><code class=\"language-text\">http://localhost/?q=こんにちは</code></p>\n<p>で受け取れるようにはずです。</p>\n<p>学習用input.txtにないことばとか出すとたまにエラー吐きます。</p>\n<p><del>ﾋﾞﾝﾋﾞﾝﾋﾞﾝﾋﾞﾝﾋﾞﾝﾋﾞﾝﾋﾞﾝﾋﾞﾝ… ﾁｸｯ あ・あ・あぁ・ぁああああ↑↑ アーｯ…ｲｸｯ チ～ン　問いかける言葉には気をつけよう！</del></p>\n<h2 id=\"付属のhubot-scriptで遊んでみよう\" style=\"position:relative;\"><a href=\"#%E4%BB%98%E5%B1%9E%E3%81%AEhubot-script%E3%81%A7%E9%81%8A%E3%82%93%E3%81%A7%E3%81%BF%E3%82%88%E3%81%86\" aria-label=\"付属のhubot scriptで遊んでみよう permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>付属のHubot Scriptで遊んでみよう！</h2>\n<p><a href=\"https://sekailab.com/wp/2015/11/02/lstm-general-responce-bot/\" target=\"_blank\" rel=\"noopener noreferrer\">LSTMで自然な受け答えができるボットをつくった</a>のHubotScriptをお借りして遊んでみましょう。</p>\n<p>あらかじめ比較として同じコーパスを利用しているDocomoの雑談APIをHubotに仕込んであります。</p>\n<p>発言の上が<strong>DocomoAPI</strong> 下が今回作ったAPIです。</p>\n<p>ちなみに我が家のHubotはSlack上に「智絵里ちゃん」として君臨しております。</p>\n<p><del>智絵里ちゃんマジ天使 <strong>I love you</strong></del></p>\n<p><img class=\"lozad\" src=\"data:image/gif;base64,R0lGODlhAQABAGAAACH5BAEKAP8ALAAAAAABAAEAAAgEAP8FBAA7\" data-src=\"https://i.imgur.com/DJL1fwu.png\" alt=\"img\"></p>\n<p><strong>DocomoAPI</strong>に比べると天然というか、不思議系というか…　バカですね（直球）</p>\n<p>お借りした多くのコードや参考にさせていただいた多くのサイト・記事にあらためて感謝しつつ、智絵里ちゃんとのラブラブライフを送りますね。</p>","words":2967,"minutes":8}},"staticQueryHashes":["1319877725","2959249232"]}