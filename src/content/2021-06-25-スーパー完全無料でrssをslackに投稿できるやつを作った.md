---
slug: 2021/06/25/tech-blog-spider
title: スーパー完全無料でRSSをSlackに投稿できるやつを作った
date: 2021-06-25T11:59:57.951Z
description: 貧乏人なので、完全無料でRSSを制限なくSlackできるやつがほしかったので作ることにしました。
tags:
  - RSS
  - HarperDB
  - feedparser
  - termextract
headerImage: https://i.imgur.com/QmIHfeR.jpg
templateKey: blog-post
---
貧乏人はつらいです。

## Table of Contents

```toc

```

## 皆さん、どうやって技術ネタ、キャッチアップしてますか？

皆さんはどうやって日々日進月歩な技術ネタをキャッチアップしてますか？

私はよく企業や個人が書いている技術ブログから情報を得ることが多いです。本当に技術ブログって手軽なのにすごい勉強になりますよね。

## 皆さん、どうやってブログ記事を通知してますか？

ブログ記事確認はもちろん定期的にブログに訪問するのが一番ですが、なかなか時間の取れない中でそれは酷なので何かしら皆さん工夫していると思います。

ブログの更新にあわせてTwitterを更新してくれる企業様であれば、Twitterのフォローをすればいいかもしれませんが、必ずしもそうでもないかもしれませんし、Twitterのフォローには技術以外の話題も飛び交うので、集中して記事を確認することも難しいかもしれません。

そういったときに役立つのがRSSです。RSSとは**R**ich **S**ite **S**ummaryの略で、ニュースやブログなど各種のウェブサイトの更新情報を配信するための仕組みやXMLフォーマットのことです。

RSSの更新を定期的に取得し、記事更新を教えてくれるRSSリーダーは皆さんお世話になっている人も多いのではないでしょうか？

私もGoogle Chromeに拡張としてRSSリーダーを入れていた時期もありました。

## 問題点

RSSリーダーを使って技術ブログの更新を検知する方法はおそらくデファクトスタンダードだと思いますが、個人的にちょっと問題点がありました。

それは、**通勤時間の時間をうまく使ってキャッチアップするのが面倒ということです。**

- 携帯にPCと同じRSSを登録するのがめんどくさい
- RSSリーダーを開かない
  - 電車に乗っているとTwitterやSlackを開いている時間がほぼ全て
  - Kindleで読書するのも細かく乗り換えがあって中断が多く発生するためストレス
- (RSSリーダーによって違うのかもしれませんが)タイトルを見て中身を判断するのが難しい

このような悩みがあるため、私は**Slack**の**/feed**機能を使ってRSSを購読してました。

が、しかしこれもまたもや問題点。Slackの無料ワークスペースには、Appsが10個までしか登録できないのです。(/feedもAppsを消費します)

Slackには他にもAppsをいくつか作って入れているため、実際登録できるRSSは5個くらいになってしまいちょっと心もとない感じになってしまいました。

### IFTTTはどうなの？

ちょっと詳しい人だと「じゃあIFTTT」はどうなんです？という意見が聞こえてきそうですが結果的にこちらも不採用。

理由は上記とほぼ同じで、無料版だと設定できる数に制限があるためこちらもあえなく不採用。

というより、お金出せよって声が聞こえてきますね。

## じゃあ作ろっか

ということで、作ります。

要求は次の通りのことを満たす必要があります。

- 無制限にRSSを登録できること
- 更新がある場合のみSlackに投稿すること
- SlackもAppsを消費しないこと(Custom Integration)
- できれば内容を要約したものや、OGP画像も一緒に投稿して記事の選別に役立てられる付加機能を作ること

## feedparser

今回は時間もない中だったのでサクッとPythonで作っていきます。

RSSの購読には[feedparser](https://pythonhosted.org/feedparser/)を使うと便利です。

RSS2.0だけでなく、Atomや古いRSSの形式でも難なく読み込んでくれます。

```python
import feedparser
entries = feedparser.parse('http://feedparser.org/docs/examples/rss20.xml')
for e in entries:
    print(e.title)
    print(e.link)
    print(e.summary)
```

Entry Itemへのアクセスはイテレーターになっているので取り出しもかんたんです。

RSSのEntry Itemの取り出しはこれで進めます。本当にかんたんでありがたい。

## ステート管理

RSSには記事の作成日付(Publish Date)があり、RSSの取得のたびに差分チェックとして活用することができます。

なので、以前取得した記事のPublish Dateを記憶して、更新があった場合のみ記事を取得するようにしたいのですが、それには何かしらのDB、もしくはデータ保存する仕組みが必要となります。

今回は無料という縛りがあるため、当初はGitHubのレポジトリ上にステートファイルをコミットするようにしようとも思ったのですが、コミットが伸び過ぎてしまうのは色々問題なのでやはりDBを使いたいです。

### HarperDB

HarperDBは、データ管理を容易にすることに重点を置いた分散型データベースで、ジョインを含むNoSQLとSQLをサポートしています。

NoSQLでSQLがかけるのは便利ですね！！

日本ではあまり聞きませんが、[dev.to](https://dev.to/)とかだとちょこちょこ話題に上がっております。

こちらのHarperDB、HarperDB Cloud Instanceというマネージドサービスも提供されており、インスタンスタイプを選ぶだけで、手軽にHarperDBを使うことができるようになっております。

![harperdb](https://i.imgur.com/CA1sLCU.png)

![img](https://i.imgur.com/48qXVQw.png)

え？でもお高いんじゃない？そんな声が聞こえてきますね。

なんと、今だけかもしれませんがHarperDB Cloud Instanceの一番最小のInstance構成だと無料で使うことができます！これは嬉しいですね。

| Name    | Value | 
| ------- | ----- | 
| RAM     | 0.5GB | 
| DISK    | 1GB   | 
| VERSION | 3.0.0 | 
| IOPS    | 3000  | 

正直今回の使い方ではこのレベルで十分です。

Python上でのHarperDB操作も[専用のライブラリ](https://pypi.org/project/harperdb/)が用意されているためかんたんに実装できます。

```python
test = db.search_by_hash(HARPERDB_SCHEMA, "last_published", [name], get_attributes=["time"])
for t in test:
    print(t["time"])
```

このようにNoSQLライクにHash Attributeを使って検索する感じで実装できます。もちろんValue引きも可能です。(遅くなるのかは不明だがNoSQLなら全走査になりそうなので多分遅い)

また、便利だなと思ったのはやはりSQLでの走査です。

```python
def get_entry_urls():
    return [{"name": x["name"],
             "url": x["url"],
             "icon": x["icon"]} for x in db.sql(f"select * from {HARPERDB_SCHEMA}.entry_urls")]
```

といった具合にテーブルの＊Selectやジョインなんかも書くことができます。いやはや、これは楽でいいですね。

また、CSV load機能もあり、CSVをHarperDBに食わせることもできちゃったりします。

今回はこちらの機能はRSSのEntryURL登録機能として便利に使用させていただきました。

```python
import os
import harperdb

HARPERDB_URL = os.getenv("HARPERDB_URL")
HARPERDB_USERNAME = os.getenv("HARPERDB_USERNAME")
HARPERDB_PASSWORD = os.getenv("HARPERDB_PASSWORD")
HARPERDB_SCHEMA = os.getenv("HARPERDB_SCHEMA", "prd")
FILEPATH = "entry.csv"

db = harperdb.HarperDB(
    url=HARPERDB_URL,
    username=HARPERDB_USERNAME,
    password=HARPERDB_PASSWORD,)

db.csv_data_load(HARPERDB_SCHEMA, "entry_urls", FILEPATH, action="upsert")

```
















